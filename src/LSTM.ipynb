{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmkyzWIRDhYK"
      },
      "outputs": [],
      "source": [
        "import os, pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GRU, Input, Embedding, LSTM, Dense, Concatenate, TimeDistributed, Dropout, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "import glob\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_gpu = True\n",
        "\n",
        "if not use_gpu:\n",
        "    tf.config.set_visible_devices([], 'GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "G5r-B9A9DzsJ"
      },
      "outputs": [],
      "source": [
        "file_paths = glob.glob(os.path.join(config.MidiFiles.preprocessed_csv_files, \"*.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "X_sGIuJ0H1t0"
      },
      "outputs": [],
      "source": [
        "def preprocess_file(df):\n",
        "  df['delta_time'] = np.log1p(df['delta_time'])\n",
        "  df['duration'] = np.log1p(df['duration'])\n",
        "  \n",
        "  df['note'] = df['pitch'] % 12\n",
        "  df['octave'] = df['pitch'] // 12\n",
        "\n",
        "  df['zero_delta_time'] = df['delta_time'] == 0\n",
        "  df[\"delta_time\"] = df[\"delta_time\"].replace(0, pd.NA).ffill()\n",
        "  df[\"delta_time\"] = df[\"delta_time\"].fillna(0)\n",
        "\n",
        "  df = df.drop(columns=[\"pitch\"])\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qwdsIGZFQms",
        "outputId": "b1df235f-490e-4f60-f396-84291b3f55b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [00:02<00:00, 157.47it/s]\n"
          ]
        }
      ],
      "source": [
        "pd.set_option(\"future.no_silent_downcasting\", True)\n",
        "\n",
        "songs = []\n",
        "for p in tqdm(file_paths):\n",
        "    try:\n",
        "        df = pd.read_csv(p)\n",
        "        df = preprocess_file(df)\n",
        "        songs.append(df)\n",
        "    except Exception as e:\n",
        "        print(\"Skipping\", p, e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hLc7gefONOju"
      },
      "outputs": [],
      "source": [
        "transpose_offset = config.LstmParameters.transpose_offset\n",
        "\n",
        "seq_len = config.LstmParameters.seq_len\n",
        "num_features = config.LstmParameters.num_features\n",
        "\n",
        "batch_size = config.LstmParameters.batch_size\n",
        "epochs = config.LstmParameters.epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SIkNH61NFwwH"
      },
      "outputs": [],
      "source": [
        "def sequence_generator(songs, seq_len):\n",
        "    for offset in range(transpose_offset):\n",
        "        for df in songs:\n",
        "            copied_df = df.copy()\n",
        "            \n",
        "            copied_df[\"note\"] = (copied_df[\"note\"] + offset) % 12\n",
        "\n",
        "            # one-hot encoding the notes\n",
        "            notes = copied_df[\"note\"].astype(int).values\n",
        "            notes_onehot = np.eye(12, dtype=np.float32)[notes]  # shape (len, 12)\n",
        "\n",
        "            # one-hot encoding the octave\n",
        "            octaves = copied_df[\"octave\"].astype(int).values\n",
        "            octaves_onehot = np.eye(10, dtype=np.float32)[octaves]  # shape (len, 10)\n",
        "\n",
        "            # drop old note column and replace with one-hot\n",
        "            copied_df = copied_df.drop(columns=[\"note\", \"octave\"])\n",
        "            data = np.hstack([copied_df.values.astype(np.float32), notes_onehot, octaves_onehot])\n",
        "            # print(data.shape)\n",
        "\n",
        "            # split features\n",
        "            # features: delta_time, arg1-3, Control_c, Note_on_c, Program_c, Pitch_bend_c\n",
        "            X_seq = data[:, :]  # all features\n",
        "            for i in range(len(data) - seq_len):\n",
        "                X = X_seq[i:i+seq_len]\n",
        "                y = X_seq[i+seq_len]\n",
        "\n",
        "                # Separate outputs\n",
        "                y_delta = y[0:1]\n",
        "                y_duration = y[1:2]\n",
        "                y_zero_delta_time = y[2:3]\n",
        "\n",
        "                # note_idx = int(y[3])\n",
        "                # y_note = np.zeros(12, dtype=np.float32)\n",
        "                # y_note[note_idx] = 1.0  \n",
        "                y_note = y[3:15]\n",
        "                y_octave = y[15:25]\n",
        "\n",
        "                yield X, {\n",
        "                    'out_delta': y_delta,\n",
        "                    'out_duration': y_duration,\n",
        "                    'out_zero_delta': y_zero_delta_time,\n",
        "                    'out_note': y_note,\n",
        "                    'out_octave': y_octave,\n",
        "                }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GE2F9CzlF4Is"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: sequence_generator(songs, seq_len),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(seq_len, num_features), dtype=tf.float32),\n",
        "        {\n",
        "            'out_delta': tf.TensorSpec(shape=(1,), dtype=tf.float32),\n",
        "            'out_duration': tf.TensorSpec(shape=(1,), dtype=tf.float32),\n",
        "            'out_zero_delta': tf.TensorSpec(shape=(1,), dtype=tf.float32),\n",
        "            'out_note': tf.TensorSpec(shape=(12,), dtype=tf.float32),\n",
        "            'out_octave': tf.TensorSpec(shape=(10,), dtype=tf.float32),\n",
        "        }\n",
        "    )\n",
        ")\n",
        "\n",
        "dataset = dataset.shuffle(10000, seed=42).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,101,824</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_delta (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_duration        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_zero_delta      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_note (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,084</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_octave (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m25\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m1,101,824\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m2,099,200\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_delta (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_duration        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_zero_delta      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_note (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │      \u001b[38;5;34m3,084\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ out_octave (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m2,570\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,439,001</span> (20.75 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,439,001\u001b[0m (20.75 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,439,001</span> (20.75 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,439,001\u001b[0m (20.75 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from src.lstm import get_model\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "WDCTu5SPNhHI",
        "outputId": "424ec4af-8ade-4594-dd03-72a27a8483e1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import re\n",
        "\n",
        "output_path = config.MidiFiles.weights_path\n",
        "\n",
        "checkpoint_filepath = output_path / 'lstm-{epoch:02d}-{loss:.4f}.weights.h5'\n",
        "\n",
        "last_epoch = 0\n",
        "files = [f for f in os.listdir(output_path) if f.endswith(\".weights.h5\")]\n",
        "if files:\n",
        "    # Extract epoch numbers\n",
        "    epochs = [int(re.search(r\"lstm-(\\d+)-\", f).group(1)) for f in files]\n",
        "    last_epoch = max(epochs)\n",
        "\n",
        "    # Pick last checkpoint\n",
        "    last_checkpoint = [f for f in files if f\"lstm-{last_epoch:02d}-\" in f][0]\n",
        "    last_checkpoint_path = os.path.join(output_path, last_checkpoint)\n",
        "\n",
        "    print(f\"Resuming from checkpoint: {last_checkpoint_path}\")\n",
        "\n",
        "    model.load_weights(last_checkpoint_path)\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    save_best_only=False, \n",
        "    monitor='loss',\n",
        "    mode='min',     # Mode for the monitor metric ('min' for loss, 'max' for accuracy)\n",
        "    save_freq='epoch' # Save after each epoch\n",
        ")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    dataset, \n",
        "    epochs=epochs, \n",
        "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
        "    initial_epoch=last_epoch\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best weights file: lstm-03-2.5557.weights.h5\n",
            "Minimum loss: 2.5557\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "models = os.listdir(config.MidiFiles.weights_path)\n",
        "\n",
        "pattern = r\"lstm-(\\d+)-([\\d.]+)\\.weights.h5\"\n",
        "\n",
        "min_loss = float('inf')\n",
        "best_file = None\n",
        "\n",
        "for filename in models:\n",
        "    match = re.match(pattern, filename)\n",
        "    if match:\n",
        "        epoch = int(match.group(1))\n",
        "        loss = float(match.group(2))\n",
        "        if loss < min_loss:\n",
        "            min_loss = loss\n",
        "            best_file = filename\n",
        "\n",
        "print(\"Best weights file:\", best_file)\n",
        "print(\"Minimum loss:\", min_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/arshia/.pyenv/versions/main-env/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 48 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "model.load_weights(config.MidiFiles.weights_path + '/' + best_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for batch in dataset.take(1):  # take one batch\n",
        "    X_seed, y_seed = batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed_sequence = X_seed[10] \n",
        "seed_sequence = tf.expand_dims(seed_sequence, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "generated_sequence = tf.identity(seed_sequence)\n",
        "sequence_length = seed_sequence.shape[1]\n",
        "num_steps_to_generate = 250\n",
        "\n",
        "for _ in range(num_steps_to_generate):\n",
        "    input_seq = generated_sequence[:, -sequence_length:, :]\n",
        "    \n",
        "    # next_pred = model(input_seq)\n",
        "\n",
        "    pred_delta, pred_velocity, pred_duration, pred_note, pred_octave, pred_zero_delta = model(input_seq)\n",
        "\n",
        "    # Optionally sample instead of taking raw predictions\n",
        "    # For categorical note output: sample from softmax distribution\n",
        "    note_probs = tf.squeeze(pred_note)  # shape (12,)\n",
        "    note_index = tf.random.categorical(tf.math.log([note_probs]), 1)\n",
        "    note_onehot = tf.one_hot(tf.squeeze(note_index), depth=12)\n",
        "\n",
        "    # Concatenate all outputs into one step vector\n",
        "    next_step = tf.concat([\n",
        "        tf.cast(pred_delta, tf.float32),       # (batch, 1)\n",
        "        tf.cast(pred_velocity, tf.float32),    # (batch, 1)\n",
        "        tf.cast(pred_duration, tf.float32),    # (batch, 1)\n",
        "        tf.cast(pred_octave, tf.float32),      # (batch, 1)\n",
        "        tf.cast(pred_zero_delta, tf.float32),   # (batch, 1)\n",
        "        tf.cast(note_onehot[tf.newaxis, :], tf.float32),  # (1, 12)\n",
        "    ], axis=-1)  # shape (batch, 17)\n",
        "\n",
        "    # Append to the sequence\n",
        "    generated_sequence = tf.concat(\n",
        "        [generated_sequence, next_step[:, tf.newaxis, :]], axis=1\n",
        "    )\n",
        "\n",
        "\n",
        "    # next_step = tf.concat([tf.cast(next_pred[0], tf.float32),\n",
        "    #                        tf.cast(next_pred[1], tf.float32),\n",
        "    #                        tf.cast(next_pred[2], tf.float32),\n",
        "    #                        tf.cast(next_pred[3], tf.float32)], axis=-1) \n",
        "    # # next_step = next_pred[:, -1:]  # take only the last timestep\n",
        "\n",
        "    # # Append to generated sequence\n",
        "    # generated_sequence = tf.concat([generated_sequence, next_step[:, tf.newaxis, :]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "seq = generated_sequence[0].numpy()  # remove batch dimension → shape (total_steps, feature_dim)\n",
        "start = 0\n",
        "\n",
        "delta_time = seq[start:, 0]\n",
        "velocity = seq[start:, 1]\n",
        "duration = seq[start:, 2]\n",
        "octave = seq[start:, 3]\n",
        "zero_delta_time = seq[start:, 4]\n",
        "note_onehot = seq[start:, 5:17]  # 12 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "note = np.argmax(note_onehot, axis=1)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"delta_time\": delta_time,\n",
        "    \"velocity\": velocity,\n",
        "    \"duration\": duration,\n",
        "    \"note\": note,\n",
        "    \"octave\": octave,\n",
        "    \"zero_delta_time\": zero_delta_time,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reverse_preprocess_file(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    df['delta_time'] = np.expm1(df['delta_time']).round().astype(int)\n",
        "    df['duration'] = np.expm1(df['duration']).round().astype(int)\n",
        "\n",
        "    df[\"velocity\"] = 127\n",
        "    df[\"velocity\"] = df[\"velocity\"].round().astype(int)\n",
        "    df[\"octave\"] = df[\"octave\"].round().astype(int)\n",
        "\n",
        "    df.loc[df[\"zero_delta_time\"] > 0.5, \"delta_time\"] = 0\n",
        "\n",
        "    df['pitch'] = df['octave'] * 12 + df[\"note\"]\n",
        "    \n",
        "    df.drop([\"zero_delta_time\", 'note', 'octave'], inplace=True, axis=1)\n",
        "\n",
        "    df = df[['delta_time', 'pitch', 'velocity', 'duration']]\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "reversed_df = reverse_preprocess_file(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "pd.options.display.max_rows = None\n",
        "display(reversed_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "reversed_df.to_csv(\"generated_music.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "main-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
